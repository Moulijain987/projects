{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9770307,"sourceType":"datasetVersion","datasetId":5984275}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T09:03:36.653253Z","iopub.execute_input":"2024-12-18T09:03:36.654138Z","iopub.status.idle":"2024-12-18T09:03:37.353831Z","shell.execute_reply.started":"2024-12-18T09:03:36.654098Z","shell.execute_reply":"2024-12-18T09:03:37.352459Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sat-by-year-and-gender-1967-2001/SAT_by_Year_Gender_1967_2001.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\ndata=pd.read_csv('/kaggle/input/sat-by-year-and-gender-1967-2001/SAT_by_Year_Gender_1967_2001.csv')\nprint(data.head)","metadata":{"execution":{"iopub.status.busy":"2024-12-18T09:03:49.990731Z","iopub.execute_input":"2024-12-18T09:03:49.991547Z","iopub.status.idle":"2024-12-18T09:03:51.250323Z","shell.execute_reply.started":"2024-12-18T09:03:49.991484Z","shell.execute_reply":"2024-12-18T09:03:51.249239Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<bound method NDFrame.head of     Year  M_verbal  F_verbal  M_math  F_math  A_verbal  A_math  M_averages  \\\n0   1967       540       545     535     495       543     516         538   \n1   1968       541       543     533     497       543     516         537   \n2   1969       536       543     534     498       540     517         535   \n3   1970       536       538     531     493       537     512         534   \n4   1971       531       534     529     494       532     513         530   \n5   1972       531       529     527     489       530     509         529   \n6   1973       523       521     525     489       523     506         524   \n7   1974       524       520     524     488       521     505         524   \n8   1975       515       509     518     479       512     498         516   \n9   1976       511       508     520     475       509     497         516   \n10  1977       509       505     520     474       507     496         514   \n11  1978       511       503     517     474       507     494         514   \n12  1979       509       501     516     473       505     493         512   \n13  1980       506       498     515     473       502     492         510   \n14  1981       508       496     516     473       502     492         512   \n15  1982       509       499     516     473       504     493         512   \n16  1983       508       498     516     474       503     494         512   \n17  1984       511       498     518     478       504     497         514   \n18  1985       514       503     522     480       509     500         518   \n19  1986       515       504     523     479       509     500         519   \n20  1987       512       502     523     481       507     501         518   \n21  1988       512       499     521     483       505     501         516   \n22  1989       510       498     523     482       504     502         516   \n23  1990       505       496     521     483       500     501         513   \n24  1991       503       495     520     482       499     500         512   \n25  1992       504       496     521     484       500     501         512   \n26  1993       504       497     524     484       500     503         514   \n27  1994       501       497     523     487       499     504         512   \n28  1995       505       502     525     490       504     506         515   \n29  1996       507       503     527     492       505     508         517   \n30  1997       507       503     530     494       505     511         518   \n31  1998       509       502     531     496       505     512         520   \n32  1999       509       502     531     495       505     511         520   \n33  2000       507       504     533     498       505     514         520   \n34  2001       509       502     533     498       506     514         521   \n\n    F_averages  A_averages  \n0          520         529  \n1          520         528  \n2          520         528  \n3          516         524  \n4          514         522  \n5          509         519  \n6          505         514  \n7          504         514  \n8          494         505  \n9          492         504  \n10         490         502  \n11         488         501  \n12         487         500  \n13         486         498  \n14         484         498  \n15         486         499  \n16         486         499  \n17         488         501  \n18         492         505  \n19         492         505  \n20         492         504  \n21         491         504  \n22         490         503  \n23         490         501  \n24         488         500  \n25         490         501  \n26         490         502  \n27         492         502  \n28         496         506  \n29         498         507  \n30         498         508  \n31         499         510  \n32         498         509  \n33         501         510  \n34         500         510  >\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-12-07T16:06:45.844420Z","iopub.execute_input":"2024-12-07T16:06:45.844859Z","iopub.status.idle":"2024-12-07T16:06:45.894649Z","shell.execute_reply.started":"2024-12-07T16:06:45.844825Z","shell.execute_reply":"2024-12-07T16:06:45.893491Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"              Year    M_verbal    F_verbal      M_math      F_math  \\\ncount    35.000000   35.000000   35.000000   35.000000   35.000000   \nmean   1984.000000  514.057143  508.371429  524.028571  485.057143   \nstd      10.246951   11.206466   15.262576    6.021949    8.653265   \nmin    1967.000000  501.000000  495.000000  515.000000  473.000000   \n25%    1975.500000  507.000000  498.000000  520.000000  478.500000   \n50%    1984.000000  509.000000  502.000000  523.000000  484.000000   \n75%    1992.500000  515.000000  508.500000  529.500000  493.500000   \nmax    2001.000000  541.000000  545.000000  535.000000  498.000000   \n\n         A_verbal      A_math  M_averages  F_averages  A_averages  \ncount   35.000000   35.000000   35.000000   35.000000   35.000000  \nmean   511.171429  503.685714  518.971429  496.742857  507.771429  \nstd     13.307419    7.722280    7.789456   10.592291    9.068646  \nmin    499.000000  492.000000  510.000000  484.000000  498.000000  \n25%    504.000000  497.500000  513.500000  490.000000  501.000000  \n50%    505.000000  502.000000  516.000000  492.000000  505.000000  \n75%    510.500000  511.000000  520.500000  500.500000  510.000000  \nmax    543.000000  517.000000  538.000000  520.000000  529.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>M_verbal</th>\n      <th>F_verbal</th>\n      <th>M_math</th>\n      <th>F_math</th>\n      <th>A_verbal</th>\n      <th>A_math</th>\n      <th>M_averages</th>\n      <th>F_averages</th>\n      <th>A_averages</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n      <td>35.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1984.000000</td>\n      <td>514.057143</td>\n      <td>508.371429</td>\n      <td>524.028571</td>\n      <td>485.057143</td>\n      <td>511.171429</td>\n      <td>503.685714</td>\n      <td>518.971429</td>\n      <td>496.742857</td>\n      <td>507.771429</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10.246951</td>\n      <td>11.206466</td>\n      <td>15.262576</td>\n      <td>6.021949</td>\n      <td>8.653265</td>\n      <td>13.307419</td>\n      <td>7.722280</td>\n      <td>7.789456</td>\n      <td>10.592291</td>\n      <td>9.068646</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1967.000000</td>\n      <td>501.000000</td>\n      <td>495.000000</td>\n      <td>515.000000</td>\n      <td>473.000000</td>\n      <td>499.000000</td>\n      <td>492.000000</td>\n      <td>510.000000</td>\n      <td>484.000000</td>\n      <td>498.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1975.500000</td>\n      <td>507.000000</td>\n      <td>498.000000</td>\n      <td>520.000000</td>\n      <td>478.500000</td>\n      <td>504.000000</td>\n      <td>497.500000</td>\n      <td>513.500000</td>\n      <td>490.000000</td>\n      <td>501.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1984.000000</td>\n      <td>509.000000</td>\n      <td>502.000000</td>\n      <td>523.000000</td>\n      <td>484.000000</td>\n      <td>505.000000</td>\n      <td>502.000000</td>\n      <td>516.000000</td>\n      <td>492.000000</td>\n      <td>505.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1992.500000</td>\n      <td>515.000000</td>\n      <td>508.500000</td>\n      <td>529.500000</td>\n      <td>493.500000</td>\n      <td>510.500000</td>\n      <td>511.000000</td>\n      <td>520.500000</td>\n      <td>500.500000</td>\n      <td>510.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2001.000000</td>\n      <td>541.000000</td>\n      <td>545.000000</td>\n      <td>535.000000</td>\n      <td>498.000000</td>\n      <td>543.000000</td>\n      <td>517.000000</td>\n      <td>538.000000</td>\n      <td>520.000000</td>\n      <td>529.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.interpolate import lagrange\nimport numpy as np\ny = list(data['Year'])\na = list(data['A_averages'])\nm = list(data['M_averages'])\nf = list(data['F_averages'])\n\n# Rescale years\ny_rescaled = [year - min(y) for year in y]\n\n# Piecewise Lagrange interpolation\ndef nearest_neighbors(x, values, year, k=5):\n    distances = np.abs(np.array(x) - year)\n    indices = np.argsort(distances)[:k]\n    return [x[i] for i in indices], [values[i] for i in indices]\n\ndef lagrange_predict(year, x, values, k=5):\n    x_subset, values_subset = nearest_neighbors(x, values, year, k)\n    poly = lagrange(x_subset, values_subset)\n    return poly(year)\n\n# User input\npy = int(input('Enter year for which you want to predict average: '))\npt = int(input('What do you want to predict:\\n 1. Male Average \\n 2. Female Average \\n 3. Total Average \\n 4. All \\n 5. Exit \\n Your choice: '))\n\n# Predict\nif pt == 1:\n    print('Average Score of Male students in SAT in the year', py, 'is:', round(lagrange_predict(py - min(y), y_rescaled, m), 6))\nelif pt == 2:\n    print('Average Score of Female students in SAT in the year', py, 'is:', round(lagrange_predict(py - min(y), y_rescaled, f), 6))\nelif pt == 3:\n    print('Average Score of all students in SAT in the year', py, 'is:', round(lagrange_predict(py - min(y), y_rescaled, a), 6))\nelif pt == 4:\n    print('Average Score of Male students in SAT in the year', py, 'is:', round(lagrange_predict(py - min(y), y_rescaled, m), 6))\n    print('Average Score of Female students in SAT in the year', py, 'is:', round(lagrange_predict(py - min(y), y_rescaled, f), 6))\n    print('Average Score of all students in SAT in the year', py, 'is:', round(lagrange_predict(py - min(y), y_rescaled, a), 6))\nelif pt == 5:\n    print(\"Exiting the program.\")\n    exit()\nelse:\n    print(\"Invalid choice! Please select a valid option.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:08:26.746946Z","iopub.execute_input":"2024-12-07T16:08:26.747324Z","iopub.status.idle":"2024-12-07T16:08:36.219482Z","shell.execute_reply.started":"2024-12-07T16:08:26.747292Z","shell.execute_reply":"2024-12-07T16:08:36.218398Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter year for which you want to predict average:  2005\nWhat do you want to predict:\n 1. Male Average \n 2. Female Average \n 3. Total Average \n 4. All \n 5. Exit \n Your choice:  3\n"},{"name":"stdout","text":"Average Score of all students in SAT in the year 2005 is: 160.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"BAR GRAPH\navg_male = data['M_averages'].mean()\navg_female = data['F_averages'].mean()\n\nplt.figure(figsize=(6, 6))\nplt.bar(['Male Average', 'Female Average'], [avg_male, avg_female], color=['blue','violet'])\nplt.ylabel(\"Average Score\")\nplt.title(\"Average SAT Scores by Gender\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-27T08:13:17.511497Z","iopub.execute_input":"2024-11-27T08:13:17.511968Z","iopub.status.idle":"2024-11-27T08:13:17.757336Z","shell.execute_reply.started":"2024-11-27T08:13:17.511920Z","shell.execute_reply":"2024-11-27T08:13:17.756335Z"}}},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/sat-by-year-and-gender-1967-2001/SAT_by_Year_Gender_1967_2001.csv')\ny = list(data['Year'])\na = list(data['A_averages'])\nm = list(data['M_averages'])\nf = list(data['F_averages'])\ndef lagrange_interpolation(year, values):\n    a_est = 0\n    n = len(y)\n    for i in range(n):\n        l_i = 1\n        for j in range(n):\n            if j != i:\n                l_i *= (year - y[j]) / (y[i] - y[j])\n        a_est += l_i * values[i]\n    return a_est\n\n# Input from user\npy = int(input('Enter year for which you want to predict average: '))\npt = int(input('What do you want to predict:\\n 1. Male Average \\n 2. Female Average \\n 3. Total Average \\n 4. All \\n 5. Exit \\n Your choice: '))\n\nif pt == 1:\n    print('Average Score of Male students appearing in SAT in the year', py, 'is:', round(lagrange_interpolation(py, m), 6))\nelif pt == 2:\n    print('Average Score of Female students appearing in SAT in the year', py, 'is:', round(lagrange_interpolation(py, f), 6))\nelif pt == 3:\n    print('Average Score of all students appearing in SAT in the year', py, 'is:', round(lagrange_interpolation(py, a), 6))\nelif pt == 4:\n    print('Average Score of Male students appearing in SAT in the year', py, 'is:', round(lagrange_interpolation(py, m), 6))\n    print('Average Score of Female students appearing in SAT in the year', py, 'is:', round(lagrange_interpolation(py, f), 6))\n    print('Average Score of all students appearing in SAT in the year', py, 'is:', round(lagrange_interpolation(py, a), 6))\nelif pt == 5:\n    print(\"Exiting the program.\")\n    exit()\nelse:\n    print(\"Invalid choice! Please select a valid option.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:07:05.116864Z","iopub.execute_input":"2024-12-07T16:07:05.117274Z","iopub.status.idle":"2024-12-07T16:07:19.511205Z","shell.execute_reply.started":"2024-12-07T16:07:05.117239Z","shell.execute_reply":"2024-12-07T16:07:19.510050Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter year for which you want to predict average:  2005\nWhat do you want to predict:\n 1. Male Average \n 2. Female Average \n 3. Total Average \n 4. All \n 5. Exit \n Your choice:  3\n"},{"name":"stdout","text":"Average Score of all students appearing in SAT in the year 2005 is: 16581637805369.477\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"X = data[['Year']]\nY = data['A_averages']\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.3, random_state=0)\nmodelr = RandomForestRegressor(n_estimators=100, random_state=42)\nmodelr.fit(X_train, y_train)\npred = modelr.predict(X_valid)\nmae=mean_absolute_error(y_valid, pred)\nprint('ERROR -',mae)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T08:11:24.653199Z","iopub.execute_input":"2024-11-27T08:11:24.653594Z","iopub.status.idle":"2024-11-27T08:11:24.863581Z","shell.execute_reply.started":"2024-11-27T08:11:24.653562Z","shell.execute_reply":"2024-11-27T08:11:24.862261Z"}},"outputs":[{"name":"stdout","text":"ERROR - 0.9181818181818254\n","output_type":"stream"}],"execution_count":205},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_train, y_train)\npreds = model.predict(X_valid)\nmae=mean_absolute_error(y_valid, preds)\nprint('ERROR -',mae)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T08:11:24.866569Z","iopub.execute_input":"2024-11-27T08:11:24.867308Z","iopub.status.idle":"2024-11-27T08:11:24.882980Z","shell.execute_reply.started":"2024-11-27T08:11:24.867248Z","shell.execute_reply":"2024-11-27T08:11:24.879867Z"}},"outputs":[{"name":"stdout","text":"ERROR - 6.664605384418265\n","output_type":"stream"}],"execution_count":206},{"cell_type":"code","source":"future_years = pd.DataFrame({'Year':range(2010, 2030)})\npredl=model.predict(future_years)\npredr=modelr.predict(future_years)\nfuture_years['A_averagesl']=predl\nfuture_years['A_averagesr']=predr \nprint(future_years)\nprint()\nprint(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T08:11:24.887063Z","iopub.execute_input":"2024-11-27T08:11:24.887538Z","iopub.status.idle":"2024-11-27T08:11:24.948038Z","shell.execute_reply.started":"2024-11-27T08:11:24.887499Z","shell.execute_reply":"2024-11-27T08:11:24.945733Z"}},"outputs":[{"name":"stdout","text":"    Year  A_averagesl  A_averagesr\n0   2010   497.430748       509.67\n1   2011   496.992022       509.67\n2   2012   496.553296       509.67\n3   2013   496.114570       509.67\n4   2014   495.675844       509.67\n5   2015   495.237118       509.67\n6   2016   494.798392       509.67\n7   2017   494.359666       509.67\n8   2018   493.920941       509.67\n9   2019   493.482215       509.67\n10  2020   493.043489       509.67\n11  2021   492.604763       509.67\n12  2022   492.166037       509.67\n13  2023   491.727311       509.67\n14  2024   491.288585       509.67\n15  2025   490.849859       509.67\n16  2026   490.411133       509.67\n17  2027   489.972407       509.67\n18  2028   489.533681       509.67\n19  2029   489.094955       509.67\n\n    Year  M_verbal  F_verbal  M_math  F_math  A_verbal  A_math  M_averages  \\\n0   1967       540       545     535     495       543     516         538   \n1   1968       541       543     533     497       543     516         537   \n2   1969       536       543     534     498       540     517         535   \n3   1970       536       538     531     493       537     512         534   \n4   1971       531       534     529     494       532     513         530   \n5   1972       531       529     527     489       530     509         529   \n6   1973       523       521     525     489       523     506         524   \n7   1974       524       520     524     488       521     505         524   \n8   1975       515       509     518     479       512     498         516   \n9   1976       511       508     520     475       509     497         516   \n10  1977       509       505     520     474       507     496         514   \n11  1978       511       503     517     474       507     494         514   \n12  1979       509       501     516     473       505     493         512   \n13  1980       506       498     515     473       502     492         510   \n14  1981       508       496     516     473       502     492         512   \n15  1982       509       499     516     473       504     493         512   \n16  1983       508       498     516     474       503     494         512   \n17  1984       511       498     518     478       504     497         514   \n18  1985       514       503     522     480       509     500         518   \n19  1986       515       504     523     479       509     500         519   \n20  1987       512       502     523     481       507     501         518   \n21  1988       512       499     521     483       505     501         516   \n22  1989       510       498     523     482       504     502         516   \n23  1990       505       496     521     483       500     501         513   \n24  1991       503       495     520     482       499     500         512   \n25  1992       504       496     521     484       500     501         512   \n26  1993       504       497     524     484       500     503         514   \n27  1994       501       497     523     487       499     504         512   \n28  1995       505       502     525     490       504     506         515   \n29  1996       507       503     527     492       505     508         517   \n30  1997       507       503     530     494       505     511         518   \n31  1998       509       502     531     496       505     512         520   \n32  1999       509       502     531     495       505     511         520   \n33  2000       507       504     533     498       505     514         520   \n34  2001       509       502     533     498       506     514         521   \n\n    F_averages  A_averages  \n0          520         529  \n1          520         528  \n2          520         528  \n3          516         524  \n4          514         522  \n5          509         519  \n6          505         514  \n7          504         514  \n8          494         505  \n9          492         504  \n10         490         502  \n11         488         501  \n12         487         500  \n13         486         498  \n14         484         498  \n15         486         499  \n16         486         499  \n17         488         501  \n18         492         505  \n19         492         505  \n20         492         504  \n21         491         504  \n22         490         503  \n23         490         501  \n24         488         500  \n25         490         501  \n26         490         502  \n27         492         502  \n28         496         506  \n29         498         507  \n30         498         508  \n31         499         510  \n32         498         509  \n33         501         510  \n34         500         510  \n","output_type":"stream"}],"execution_count":207}]}